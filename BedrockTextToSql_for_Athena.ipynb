{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc4741b-a14c-40fd-9ac0-a3bd07633747",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Building  Text-to-SQL capability to Amazon Athena using Amazon Bedrock\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Objective](#Objective)\n",
    "1. [Background](#Background-(Problem-Description-and-Approach))\n",
    "1. [Overall Workflow](#Overall-Workflow)\n",
    "1. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5453ed1-3da0-4c03-a376-e90e06c8a7eb",
   "metadata": {},
   "source": [
    "\n",
    "## Objective\n",
    "\n",
    "This notebook shows is to provide the code snippets within an executable flow from [this AWS Blog post](https://aws.amazon.com/blogs/machine-learning/build-a-robust-text-to-sql-solution-generating-complex-queries-self-correcting-and-querying-diverse-data-sources/).\n",
    "\n",
    "## Background (Problem Description and Approach)\n",
    "\n",
    "- **Problem statement**: \n",
    "\n",
    "Text-to-SQL solutions aim to generate SQL queries from natural language to enable non-technical users to access and analyze data. However, existing solutions face challenges related to ambiguity in natural language, needing to recreate capabilities for different databases, and collecting comprehensive metadata. The proposed solution in the text aims to address these challenges by incorporating metadata from AWS Glue Data Catalog, evaluating and correcting generated SQL queries using Amazon Athena feedback with multi-pass prompting, and leveraging Athena's support for diverse data sources.\n",
    "\n",
    "- **Our approach**: \n",
    "\n",
    "[`RAG`] The [RAG approach](https://aws.amazon.com/what-is/retrieval-augmented-generation/) offers several advantages. First, it gives up-to-date, precise responses. Rather than relying only on fixed, outdated training data, RAG utilizes current external sources to formulate its answers. In this solution, we used RAG to increase the accuracy of table name from [AWS Glue Data Catalog](https://docs.aws.amazon.com/glue/latest/dg/catalog-and-crawler.html). \n",
    "\n",
    "[`Vector Store`] [Amazon OpenSearch](https://aws.amazon.com/opensearch-service/) offers three vector engines to choose from, each catering to different use cases.Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors. This code bases used [FAISS for similiarity search](https://aws.amazon.com/about-aws/whats-new/2023/10/amazon-opensearch-service-vector-query-filters-faiss/).\n",
    "\n",
    "[`Amazon Athena`] [Amazon Athena](https://aws.amazon.com/athena/) is a serverless, interactive analytics service built on open-source frameworks, supporting open-table and file formats. Athena provides a simplified, flexible way to analyze petabytes of data where it lives. In this solution, we used Amazon Athena as the SQL engine to \n",
    "\n",
    "[`Amazon Bedrock`] [Amazon Bedrock](https://aws.amazon.com/bedrock/) is a fully managed service that offers a choice of high-performing foundation models (FMs) from leading AI companies like AI21 Labs, Anthropic, Cohere, Meta, Stability AI, and Amazon via a single API, along with a broad set of capabilities you need to build generative AI applications with security, privacy, and responsible AI.\n",
    "\n",
    "We used Bedrock with multi-step / multi-pass component which allows the LLM to correct the generated SQL query for accuracy. Here, the generated SQL is sent for syntax errors. We use Athena error messages to enrich our prompt for the LLM for more accurate and effective corrections in the generated SQL.\n",
    "\n",
    "- *[RAG on AWS](https://aws.amazon.com/what-is/retrieval-augmented-generation/)*\n",
    "- *[The langchain OpenSearch documentation](https://python.langchain.com/en/latest/ecosystem/opensearch.html)*\n",
    "- *[Amazon OpenSearch service documentation](https://docs.aws.amazon.com/opensearch-service/index.html)*\n",
    "- *[Amazon OpenSearch supports efficient vector](https://aws.amazon.com/about-aws/whats-new/2023/10/amazon-opensearch-service-vector-query-filters-faiss/)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e68cc7-f452-4c88-9b49-4c10b069ce0c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overall Workflow\n",
    "\n",
    "**Prerequisite**\n",
    "\n",
    "The following are prerequisites that needs to be accomplised before executing this notebook.\n",
    "This Notebook can be executed via a Sagemaker instance or via a VS Code editor\n",
    "- Create a role having access to bedrock, glue,athena, s3,lakeformation. \n",
    "- Assign the role to the Sagemaker instance or to the instance where VS Code editor is running\n",
    "- Glue Database and tables. Provided spark notebook to create.\n",
    "- An Amazon OpenSearch cluster for storing embeddings.Here Opensearch credenitals are in notebooks. However Opensearch cluster's access credentials (username and password) can be stored in AWS Secrets Mananger by following steps described [here](https://docs.aws.amazon.com/secretsmanager/latest/userguide/managing-secrets.html).\n",
    "\n",
    "**The  workflow for this notebook is as follows:**\n",
    "*Please read [Readme.md](https://github.com/aws-samples/text-to-sql-for-athena/blob/claude3branch/README.md) to learn about the detailed steps*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994fd3e5-416d-4e4a-bfaf-faad2b53dc0c",
   "metadata": {},
   "source": [
    "##### Step 1: Setup\n",
    "Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efc3af34-9c4b-4e95-9147-cf498a74a0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install boto3\n",
    "# !pip3 install jq\n",
    "# !pip3 install langchain\n",
    "# !pip3 install langchain-community langchain-core\n",
    "# !pip3 install pandas\n",
    "# !pip3 install opensearch-py\n",
    "# !pip3 install langchain-aws\n",
    "# !pip3 install requests-aws4auth\n",
    "# !pip3 install botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f072e-88b1-4afc-ba4a-daa49f05bcd8",
   "metadata": {},
   "source": [
    "##### Step 2: Import all modules. There are some modules in other folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef96ac35-3597-4bd8-80ca-035c6c98050b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_aws import BedrockLLM\n",
    "import traceback\n",
    "import logging\n",
    "import json\n",
    "import os,sys\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import io\n",
    "from boto_client import Clientmodules\n",
    "from llm_basemodel import LanguageModel\n",
    "from athena_execution import AthenaQueryExecute\n",
    "from openSearchVCEmbedding import EmbeddingBedrockOpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6d68a-cf48-4b7f-94c5-418f2cc8f44a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Step 3: Checking access to Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "436fb4f1-cd34-4146-bc96-da5e3608d720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large', 'modelId': 'amazon.titan-tg1-large', 'modelName': 'Titan Text Large', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}\n"
     ]
    }
   ],
   "source": [
    "session = boto3.session.Session()\n",
    "bedrock_client = session.client('bedrock')\n",
    "print(bedrock_client.list_foundation_models()['modelSummaries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2217e5-dc53-428f-b224-fb3ac9e8f952",
   "metadata": {},
   "source": [
    "##### Step 4: Invoking Athena and Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72e44bd9-8787-447a-b5e0-0961547bafef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "athena client created \n",
      "s3 client created !!\n"
     ]
    }
   ],
   "source": [
    "rqstath = AthenaQueryExecute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b0cedd-0fcb-4a3b-a7be-50bd25197230",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'text_to_sql_index'\n",
    "domain = 'https://e0hc00i67ga6mpn1xkxa.us-east-1.aoss.amazonaws.com' ##-- update here with your OpenSearch domain\n",
    "region = 'us-east-1'\n",
    "vector_name = 'embeddings_vector'\n",
    "fieldname = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af3a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bedrock runtime client created \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedrockllm\n",
      "<llm_basemodel.LanguageModel object at 0x000001B95143AD40>\n",
      "bedrock_client: <botocore.client.BedrockRuntime object at 0x000001B951439210>, language_model: <llm_basemodel.LanguageModel object at 0x000001B95143AD40>, llm: client=<botocore.client.BedrockRuntime object at 0x000001B951439210> model_id='anthropic.claude-v2:1' model_kwargs={'temperature': 0, 'top_k': 20, 'top_p': 1, 'stop_sequences': ['\\n\\nHuman:']}, embeddings: client=<botocore.client.BedrockRuntime object at 0x000001B951439210> region_name=None credentials_profile_name=None model_id='amazon.titan-embed-text-v2:0' model_kwargs=None endpoint_url=None normalize=False, opensearch_domain_endpoint: https://e0hc00i67ga6mpn1xkxa.us-east-1.aoss.amazonaws.com, http_auth: <requests_aws4auth.aws4auth.AWS4Auth object at 0x000001B950DFE200>, vector_name: embeddings_vector, fieldname: id\n"
     ]
    }
   ],
   "source": [
    "ebropen2 = EmbeddingBedrockOpenSearch(domain,  vector_name,  fieldname)\n",
    "if ebropen2 is None:\n",
    "    print(\"ebropen2 is null\")\n",
    "else:\n",
    "    attrs = vars(ebropen2)\n",
    "    print(', '.join(\"%s: %s\" % item for item in attrs.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73833ad4-d3e0-46a5-acd0-2e112e23fcc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Step 5: Core logic\n",
    "1. getEmbeddding : Take the input user query and vector search to find the schema from vector db created.\n",
    "2. generate_sql: Taking the input prompt, generate sql . syntax_checker helps to check the sql syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdcd87a9-f028-43ab-94a4-8d9b5b5bd163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RequestQueryBedrock:\n",
    "    def __init__(self, ebropen2):\n",
    "        self.ebropen2 = ebropen2\n",
    "        self.bedrock_client = ebropen2.bedrock_client\n",
    "        if self.bedrock_client is None:\n",
    "            self.bedrock_client = Clientmodules.createBedrockRuntimeClient()\n",
    "        else:\n",
    "            print(\"the bedrock_client is not null\")\n",
    "        self.language_model = LanguageModel(self.bedrock_client)\n",
    "        self.llm = self.language_model.llm\n",
    "\n",
    "    def getOpenSearchEmbedding(self, index_name, user_query):\n",
    "        vcindxdoc = self.ebropen2.getDocumentfromIndex(index_name=index_name)\n",
    "        document = self.ebropen2.getSimilaritySearch(user_query, vcindxdoc)\n",
    "        return self.ebropen2.get_data(document)\n",
    "\n",
    "    def generate_sql(self, prompt, max_attempt=4) -> str:\n",
    "        attempt = 0\n",
    "        error_messages = []\n",
    "        prompts = [prompt]\n",
    "        sql_query = \"\"\n",
    "\n",
    "        while attempt < max_attempt:\n",
    "            logger.info(f'Sql Generation attempt Count: {attempt + 1}')\n",
    "            try:\n",
    "                logger.info(f'we are in Try block to generate the sql and count is :{attempt + 1}')\n",
    "                generated_sql = self.llm.invoke(prompt)\n",
    "\n",
    "                # Handle AIMessage object\n",
    "                if isinstance(generated_sql, AIMessage):\n",
    "                    content = generated_sql.content\n",
    "                elif isinstance(generated_sql, str):\n",
    "                    content = generated_sql\n",
    "                else:\n",
    "                    content = str(generated_sql)\n",
    "\n",
    "                # Extract SQL query from content\n",
    "                sql_parts = content.split(\"```\")\n",
    "                if len(sql_parts) > 1:\n",
    "                    query_str = sql_parts[1]\n",
    "                else:\n",
    "                    query_str = content\n",
    "\n",
    "                query_str = \" \".join(query_str.split(\"\\n\")).strip()\n",
    "                sql_query = query_str[3:] if query_str.lower().startswith(\"sql\") else query_str\n",
    "\n",
    "                print(sql_query)\n",
    "                syntaxcheckmsg = rqstath.syntax_checker(sql_query)\n",
    "                if syntaxcheckmsg == 'Passed':\n",
    "                    logger.info(f'syntax checked for query passed in attempt number :{attempt + 1}')\n",
    "                    return sql_query\n",
    "                else:\n",
    "                    prompt = f\"\"\"{prompt}\n",
    "                        This is syntax error: {syntaxcheckmsg}.\n",
    "                        To correct this, please generate an alternative SQL query which will correct the syntax error.\n",
    "                        The updated query should take care of all the syntax issues encountered.\n",
    "                        Follow the instructions mentioned above to remediate the error.\n",
    "                        Update the below SQL query to resolve the issue:\n",
    "                        {sql_query}\n",
    "                        Make sure the updated SQL query aligns with the requirements provided in the initial question.\"\"\"\n",
    "                    prompts.append(prompt)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                logger.error('FAILED')\n",
    "                msg = str(e)\n",
    "                error_messages.append(msg)\n",
    "            finally:\n",
    "                attempt += 1\n",
    "\n",
    "        # If all attempts fail, raise an exception with details\n",
    "        raise Exception(f\"Failed to generate SQL after {max_attempt} attempts. Errors: {', '.join(error_messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cc21a1",
   "metadata": {},
   "source": [
    "##### Create an instance of  RequestQueryBedrock class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13da2f51-6032-4564-8943-3c36e55b025f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bedrock_client is not null\n",
      "bedrockllm\n"
     ]
    }
   ],
   "source": [
    "rqst = RequestQueryBedrock(ebropen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db6b4e5f-b52e-4209-aab7-403dabc61239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def userinput(user_query):\n",
    "    logger.info(f'Searching metadata from vector store')\n",
    "    vector_search_match = rqst.getOpenSearchEmbedding(index_name, user_query)\n",
    "\n",
    "    details = f\"\"\"It is important that the SQL query complies with Athena syntax.\n",
    "\n",
    "              For our testing purposes, please only use the following data source(s), database(s) and table(s):\n",
    "\n",
    "              Data Source: AWSDataCatalog\n",
    "              Database: imdb_stg\n",
    "              Tables: basics, ratings\n",
    "\n",
    "              During a join, if two column names are the same please use alias (example: basics.tconst in select\n",
    "              statement). It is also important to pay attention to and not alter column format: if a column is string,\n",
    "              then leave column formatting alone and return a value that is a string.\n",
    "\n",
    "              If you are writing CTEs then include all the required columns. While concatenating a non-string column,\n",
    "              make sure to cast the column to string format first. If you encounter any instances where we must\n",
    "              compare date columns to strings, please cast the string input as a date and format as such.\n",
    "\n",
    "              REMEMBER: Only use the data source(S), database(s), and table(s) mentioned above. In addition,\n",
    "              always include the database name along with the table name in the query.\"\"\"\n",
    "\n",
    "    final_question = \"\\n\\nHuman:\" + details + vector_search_match + user_query + \"\\n\\nAssistant:\"\n",
    "    print(\"FINAL QUESTION :::\" + final_question)\n",
    "\n",
    "    try:\n",
    "        answer = rqst.generate_sql(final_question)\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to generate SQL: {str(e)}\")\n",
    "        return None  # Or handle the error in a way that makes sense for your application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ebe772-af08-4df5-b950-3d6aa35dd1cb",
   "metadata": {},
   "source": [
    "##### Step 6: User input in Natural Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "user_query = 'How many records in our database are from the year 1892?'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Searching metadata from vector store\n",
      "Searching metadata from vector store\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"D:\\Users\\jcarhart-health\\AppData\\Local\\Temp\\1\\ipykernel_8180\\3239037324.py\", line 1, in <module>\n",
      "    querygenerated = userinput(user_query)\n",
      "  File \"D:\\Users\\jcarhart-health\\AppData\\Local\\Temp\\1\\ipykernel_8180\\2183822863.py\", line 3, in userinput\n",
      "    vector_search_match = rqst.getOpenSearchEmbedding(index_name, user_query)\n",
      "  File \"D:\\Users\\jcarhart-health\\AppData\\Local\\Temp\\1\\ipykernel_8180\\3729880947.py\", line 14, in getOpenSearchEmbedding\n",
      "    document = self.ebropen2.getSimilaritySearch(user_query, vcindxdoc)\n",
      "  File \"C:\\code\\text-to-sql-for-athena\\openSearchVCEmbedding.py\", line 138, in getSimilaritySearch\n",
      "  File \"C:\\python310\\lib\\site-packages\\langchain_community\\vectorstores\\opensearch_vector_search.py\", line 818, in similarity_search\n",
      "    docs_with_scores = self.similarity_search_with_score(\n",
      "  File \"C:\\python310\\lib\\site-packages\\langchain_community\\vectorstores\\opensearch_vector_search.py\", line 861, in similarity_search_with_score\n",
      "    return self.similarity_search_with_score_by_vector(\n",
      "  File \"C:\\python310\\lib\\site-packages\\langchain_community\\vectorstores\\opensearch_vector_search.py\", line 892, in similarity_search_with_score_by_vector\n",
      "    hits = self._raw_similarity_search_with_score_by_vector(\n",
      "  File \"C:\\python310\\lib\\site-packages\\langchain_community\\vectorstores\\opensearch_vector_search.py\", line 1049, in _raw_similarity_search_with_score_by_vector\n",
      "    response = self.client.search(index=index_name, body=search_query)\n",
      "  File \"C:\\python310\\lib\\site-packages\\opensearchpy\\client\\utils.py\", line 176, in _wrapped\n",
      "    return func(*args, params=params, headers=headers, **kwargs)\n",
      "  File \"C:\\python310\\lib\\site-packages\\opensearchpy\\client\\__init__.py\", line 2364, in search\n",
      "    return self.transport.perform_request(\n",
      "  File \"C:\\python310\\lib\\site-packages\\opensearchpy\\transport.py\", line 455, in perform_request\n",
      "    raise e\n",
      "  File \"C:\\python310\\lib\\site-packages\\opensearchpy\\transport.py\", line 416, in perform_request\n",
      "    status, headers_response, data = connection.perform_request(\n",
      "  File \"C:\\python310\\lib\\site-packages\\opensearchpy\\connection\\http_requests.py\", line 238, in perform_request\n",
      "    self._raise_error(\n",
      "  File \"C:\\python310\\lib\\site-packages\\opensearchpy\\connection\\base.py\", line 315, in _raise_error\n",
      "    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(\n",
      "opensearchpy.exceptions.AuthorizationException: AuthorizationException(403, 'Forbidden')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"C:\\python310\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"C:\\python310\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\python310\\lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\python310\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\python310\\lib\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\python310\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\python310\\lib\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\python310\\lib\\site-packages\\executing\\executing.py\", line 167, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "querygenerated = userinput(user_query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "642ee907-5f0e-4b3d-93f7-3f8b4e048555",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Step 7: Sql Query and Query Execution output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "864a622a-b0bb-4376-916b-c6d9f0949a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'querygenerated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpprint\u001B[39;00m\n\u001B[0;32m      2\u001B[0m my_printer \u001B[38;5;241m=\u001B[39m pprint\u001B[38;5;241m.\u001B[39mPrettyPrinter()\n\u001B[1;32m----> 3\u001B[0m my_printer\u001B[38;5;241m.\u001B[39mpprint(querygenerated)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'querygenerated' is not defined"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "my_printer = pprint.PrettyPrinter()\n",
    "my_printer.pprint(querygenerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3c786-171e-426c-b501-703ae39531c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryOutput = rqstath.execute_query(querygenerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1af6ad-036b-4eeb-b640-8642a75da17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(QueryOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98397d4d-9b97-4c72-8763-f2247e88cd01",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "##### Cleanup\n",
    "\n",
    "To avoid incurring future charges, delete the resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa1ade-7993-4348-a0f6-c511f1a797e7",
   "metadata": {},
   "source": [
    "##### Conclusion\n",
    "In this notebook we were able to see how to use bedrock to deploy LLM Model to generate embeddings,then ingest those embeddings into OpenSearch and finally do a similarity search for user input to the documents (embeddings) stored in OpenSearch. Please read our [AWS Blog Post](https://aws.amazon.com/blogs/machine-learning/build-a-robust-text-to-sql-solution-generating-complex-queries-self-correcting-and-querying-diverse-data-sources/) on this topic to learn more about the solution.\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
